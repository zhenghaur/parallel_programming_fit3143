{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IOvJh7lxPr5",
        "outputId": "063ae609-33b3-4f58-b7c3-10073e15c211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-IEgjdgzaeo",
        "outputId": "ee14f145-add2-49d9-8b48-af28fe9dc980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-9zg5ulku\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-9zg5ulku\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=86739e8b3c306e47c56a0e19e4b243fb0a6de2489adbef9eea5c07902cd75ecd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g2d2ubuh/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFFgIXquzgvW",
        "outputId": "bcd1f8fe-2e13-4764-db67-42592bf0c1bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuAnETHr12t-",
        "outputId": "87a8468e-d459-4c4f-c9de-9346f551a394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix size: 1024\n",
            "Sequential code: 17.254561 seconds\n",
            "Parallel code (GPGPU): 0.044867 seconds\n",
            "The matrices match.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define BLOCK_SIZE 32\n",
        "#define MATRIX_SIZE 1024\n",
        "\n",
        "typedef struct\n",
        "{\n",
        "\tint ** elem;\n",
        "} matrix;\n",
        "\n",
        "void init_matrix(matrix* m)\n",
        "{\n",
        "\tcudaMallocManaged((void**)&(m -> elem), sizeof(int*) * MATRIX_SIZE);\n",
        "\n",
        "\tfor (int i = 0; i < MATRIX_SIZE; i++)\n",
        "\t{\n",
        "\t\tcudaMallocManaged((void**)&(m -> elem[i]), sizeof(int) * MATRIX_SIZE);\n",
        "\t}\n",
        "}\n",
        "\n",
        "void add_elem(matrix m)\n",
        "{\n",
        "\tfor (int i = 0; i < MATRIX_SIZE; i++)\n",
        "\t\tfor (int j = 0; j < MATRIX_SIZE; j++)\n",
        "\t\t{\n",
        "\t\t\tm.elem[i][j] = rand() % 50;\n",
        "\t\t}\n",
        "}\n",
        "\n",
        "\n",
        "void matrix_multiply(matrix a, matrix b, matrix result)\n",
        "{\n",
        "\tfor (int i = 0; i < MATRIX_SIZE; i++)\n",
        "\t\tfor (int j = 0; j < MATRIX_SIZE; j++)\n",
        "\t\t\tfor(int k = 0; k < MATRIX_SIZE; k++)\n",
        "\t\t\t\tresult.elem[i][j] += a.elem[i][k] * b.elem[k][j];\n",
        "}\n",
        "\n",
        "__global__ void matrix_multiply_kernel(matrix a, matrix b, matrix result)\n",
        "{\n",
        "\tint bx = blockIdx.x;\n",
        "\tint by = blockIdx.y;\n",
        "\tint tx = threadIdx.x;\n",
        "\tint ty = threadIdx.y;\n",
        "\n",
        "\tint idx = bx * BLOCK_SIZE + tx;\n",
        "\tint idy = by * BLOCK_SIZE + ty;\n",
        "\n",
        "\tint sum = 0;\n",
        "\n",
        "\t// load submatrixes by blocks\n",
        "\tfor (int block = 0; block < MATRIX_SIZE; block += BLOCK_SIZE) {\n",
        "\t\t__shared__ int a_sub[BLOCK_SIZE][BLOCK_SIZE];\n",
        "\t\t__shared__ int b_sub[BLOCK_SIZE][BLOCK_SIZE];\n",
        "\t\ta_sub[tx][ty] = (idx < MATRIX_SIZE && block + ty < MATRIX_SIZE) ? a.elem[idx][block + ty] : 0;\n",
        "\t\tb_sub[tx][ty] = (block + tx < MATRIX_SIZE && idy < MATRIX_SIZE) ? b.elem[block + tx][idy] : 0;\n",
        "\n",
        "\t\t__syncthreads();\n",
        "\t\tfor (int i = 0; i < BLOCK_SIZE; i++)\n",
        "\t\t\tsum += a_sub[tx][i] * b_sub[i][ty];\n",
        "\t\t__syncthreads();\n",
        "\t}\n",
        "\n",
        "\tif (idx < MATRIX_SIZE && idy < MATRIX_SIZE)\n",
        "\t  result.elem[idx][idy] = sum;\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "void free_matrix(matrix* m) {\n",
        "\tfor (int i = 0; i < MATRIX_SIZE; i++)\n",
        "\t\tcudaFree(m -> elem[i]);\n",
        "\tcudaFree(m -> elem);\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv)\n",
        "{\n",
        "\tprintf(\"Matrix size: %d\\n\", MATRIX_SIZE);\n",
        "\n",
        "\tstruct timespec start, end;\n",
        "  double time_taken;\n",
        "\n",
        "\t// initialize matrix\n",
        "\tmatrix a, b, serial_result, cuda_result;\n",
        "\tinit_matrix(&a);\n",
        "\tinit_matrix(&b);\n",
        "\tinit_matrix(&serial_result);\n",
        "\tinit_matrix(&cuda_result);\n",
        "\n",
        "\t// add elements to matrix\n",
        "\tadd_elem(a);\n",
        "\tadd_elem(b);\n",
        "\n",
        "\t// sequential code\n",
        "  clock_gettime(CLOCK_MONOTONIC, &start);\n",
        "\tmatrix_multiply(a, b, serial_result);\n",
        "  clock_gettime(CLOCK_MONOTONIC, &end);\n",
        "  time_taken = (end.tv_sec - start.tv_sec) * 1e9;\n",
        "  time_taken = (time_taken + (end.tv_nsec - start.tv_nsec)) * 1e-9;\n",
        "  printf(\"Sequential code: %lf seconds\\n\", time_taken);\n",
        "\n",
        "\t// cuda parallel code\n",
        "\tint dim = MATRIX_SIZE / BLOCK_SIZE + 1;\n",
        "\tdim3 block(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\tdim3 grid(dim, dim);\n",
        "\n",
        "  clock_gettime(CLOCK_MONOTONIC, &start);\n",
        "\tmatrix_multiply_kernel<<<grid, block>>>(a, b, cuda_result);\n",
        "\tcudaDeviceSynchronize();\n",
        "  clock_gettime(CLOCK_MONOTONIC, &end);\n",
        "  time_taken = (end.tv_sec - start.tv_sec) * 1e9;\n",
        "  time_taken = (time_taken + (end.tv_nsec - start.tv_nsec)) * 1e-9;\n",
        "\tprintf(\"Parallel code (GPGPU): %lf seconds\\n\", time_taken);\n",
        "\n",
        "\n",
        "\t// verify results\n",
        "\tint flag = 0;\n",
        "  int i = 0;\n",
        "  while (!flag && i < MATRIX_SIZE){\n",
        "      for (int j = 0; j < MATRIX_SIZE; j++){\n",
        "          if (serial_result.elem[i][j] != cuda_result.elem[i][j]){\n",
        "              flag = 1;\n",
        "              break;\n",
        "          }\n",
        "      }\n",
        "      i++;\n",
        "  }\n",
        "\tif (!flag)\n",
        "\t\tprintf(\"The matrices match.\\n\");\n",
        "\telse\n",
        "\t\tprintf(\"The matrices do not match.\\n\");\n",
        "\n",
        "  // free memory\n",
        "\tfree_matrix(&a);\n",
        "\tfree_matrix(&b);\n",
        "\tfree_matrix(&serial_result);\n",
        "\tfree_matrix(&cuda_result);\n",
        "\treturn 0;\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
